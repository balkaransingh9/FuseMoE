{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 12:56:31.780460: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-11 12:56:31.780488: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-11 12:56:31.780515: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-11 12:56:31.806886: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/cis/home/charr165/vscode_projects/HAIM/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from MIMIC_IV_HAIM_API import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_cxr_parent = \"/cis/home/charr165/Documents/physionet.org/files/mimic-cxr-jpg/2.0.0\"\n",
    "mm_dir = \"/cis/home/charr165/Documents/multimodal\"\n",
    "\n",
    "output_dir = os.path.join(mm_dir, \"preprocessing\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = os.path.join(mimic_iv_cxr_parent, \"mimic-cxr-2.0.0-metadata.csv\")\n",
    "meta_data_df = pd.read_csv(f_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_data_df = meta_data_df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract densefeatures and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_df['densefeatures'] = None\n",
    "meta_data_df['predictions'] = None\n",
    "\n",
    "model_weights_name = \"densenet121-res224-chex\" \n",
    "model = xrv.models.DenseNet(weights = model_weights_name)\n",
    "\n",
    "for index, row in tqdm(meta_data_df.iterrows(), total=meta_data_df.shape[0]):\n",
    "    curr_subject_id = int(row['subject_id'])\n",
    "    curr_study_id = int(row['study_id'])\n",
    "    curr_dicom_id = row['dicom_id']\n",
    "\n",
    "    f_subfolder = \"p\" + str(curr_subject_id)[0:2]\n",
    "    pt_folder = \"p\" + str(curr_subject_id)\n",
    "    s_folder = \"s\" + str(curr_study_id)\n",
    "    curr_f_path = os.path.join(mimic_iv_cxr_parent, 'files', f_subfolder, pt_folder, s_folder, curr_dicom_id + \".jpg\")\n",
    "\n",
    "    if os.path.exists(curr_f_path):\n",
    "        img = skimage.io.imread(curr_f_path)\n",
    "\n",
    "        img = xrv.datasets.normalize(img, 255)\n",
    "        img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)   \n",
    "        img = img[None, :, :]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img = torch.from_numpy(img).unsqueeze(0)\n",
    "            # if cuda:\n",
    "            img = img.cuda()\n",
    "            model = model.cuda()\n",
    "            \n",
    "            # Extract dense features\n",
    "            feats = model.features(img)\n",
    "            feats = F.relu(feats, inplace=True)\n",
    "            feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "            densefeatures = feats.cpu().detach().numpy().reshape(-1)\n",
    "            meta_data_df.at[index, 'densefeatures'] = densefeatures # append to list of dense features for all images\n",
    "\n",
    "            preds = model(img).cpu()\n",
    "            predictions = preds[0].detach().numpy()\n",
    "            meta_data_df.at[index, 'predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Unnamed: 0', 'Note_folder', 'Note_file', 'Note', 'Img_Folder',\\\n",
    "     'Img_Filename', 'Rows', 'Columns', 'StudyDate', 'StudyTime', 'StudyDateForm', \\\n",
    "        'StudyTimeForm']\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in meta_data_df.columns:\n",
    "        meta_data_df.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = os.path.join(output_dir, \"cxr_embeddings.pkl\")\n",
    "meta_data_df.to_pickle(f_path)\n",
    "print(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = os.path.join(output_dir, \"cxr_embeddings.pkl\")\n",
    "df = pd.read_pickle(f_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
